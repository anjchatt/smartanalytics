{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import os\n",
    "import psycopg2\n",
    "import psycopg2.extensions\n",
    "\n",
    "from py2neo import Graph\n",
    "from twitter import Twitter, OAuth\n",
    "\n",
    "from datetime import datetime, date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import random\n",
    "import csv\n",
    "from string import strip\n",
    "from math import floor, ceil\n",
    "\n",
    "# for sending offers via gmail\n",
    "import base64\n",
    "from email.mime.image import MIMEImage\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "import smtplib\n",
    "\n",
    "# Natural language query parser\n",
    "import parse_query\n",
    "    \n",
    "import pymongo\n",
    "client = pymongo.MongoClient()\n",
    "db = client.customer_database\n",
    "\n",
    "with open('config.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "graph = Graph(config[\"neo4j\"])\n",
    "\n",
    "if 'http_proxy' in os.environ:\n",
    "    if 'https_proxy' not in os.environ:\n",
    "        os.environ[\"https_proxy\"] = os.environ[\"http_proxy\"]\n",
    "\n",
    "twitter = Twitter(auth=OAuth(config['token'], config['token_secret'], config['consumer_key'], config['consumer_secret']))\n",
    "\n",
    "field_names =  ['user_screen_name', 'user_name', 'id_str', 'created_at', \n",
    "                'sentiment', 'categories', 'text', 'klout_score', 'segment_id',\n",
    "               'got_reply', 'followers_count', 'is_agent_reply']\n",
    "\n",
    "segment_dict = {0:'-', 1:'Mass Market', 2:'Young Professional',\n",
    "                3:'Mass Afluent', 4:'Affluent', 5:'High Net Worth'}\n",
    "\n",
    "#suboffers = {} # offers dictionary\n",
    "#with open('offers_suboffers.csv', 'rb') as csvfile:\n",
    "#    file_reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "#    for row in file_reader:\n",
    "#        if len(row) >= 3:          # check if we have at least 3 field\n",
    "#            key = strip(row[0])\n",
    "#            value = strip(row[1])\n",
    "#            imageId = strip(row[2])\n",
    "#            text = strip(row[3]) if len(row) >= 4 else \"\"\n",
    "#            if key in suboffers:\n",
    "#                suboffers[key].append({\"name\": value, \"image\": imageId, \"text\":text})\n",
    "#            else:\n",
    "#                suboffers[key] = [{\"name\": value, \"image\": imageId, \"text\":text}]\n",
    "\n",
    "def get_priority_key(tw_l):\n",
    "    for tw in tw_l:\n",
    "        if not tw['is_agent_reply']:\n",
    "            p = (tw['segment_id']/2 - tw['sentiment'] - tw['got_reply']*5 +\n",
    "                tw['followers_count']/1000 + int('fraud' in tw['categories']))\n",
    "            return -p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:  [('gender', 18, 24), ('state', 28, 37), ('income', 8, 14)]\n",
      "5\n",
      "SELECT\n",
      "['gender', 'AVG(income)']\n",
      "WHERE\n",
      "[\"state in ('Minnesota')\"]\n",
      "GROUP BY\n",
      "['gender']\n",
      "LIMIT\n",
      "\n",
      "SELECT gender,AVG(income) FROM pci_customers  WHERE state in ('Minnesota') GROUP BY gender ORDER BY gender\n",
      "1:  [('state', 23, 25), ('debt_funds', 9, 18)]\n",
      "5\n",
      "3\n",
      "SELECT\n",
      "[]\n",
      "WHERE\n",
      "[\"debt_funds in ('yes')\", \"state in ('Nevada')\"]\n",
      "GROUP BY\n",
      "[]\n",
      "LIMIT\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python2.7/site-packages/numpy/core/fromnumeric.py:2645: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:  [('customer', 24, 29), ('gender', 24, 28), ('state', 33, 41), ('job', 0, 3)]\n",
      "3\n",
      "6\n",
      "SELECT\n",
      "['job', 'count(*)']\n",
      "WHERE\n",
      "[\"state in ('New York')\", \"gender in ('M')\"]\n",
      "GROUP BY\n",
      "['job']\n",
      "LIMIT\n",
      "\n",
      "SELECT job,count(*) FROM pci_customers  WHERE state in ('New York') AND gender in ('M') GROUP BY job ORDER BY job\n",
      "1:  [('gender', 18, 24), ('state', 28, 37), ('income', 8, 14)]\n",
      "5\n",
      "SELECT\n",
      "['gender', 'AVG(income)']\n",
      "WHERE\n",
      "[\"state in ('Minnesota')\"]\n",
      "GROUP BY\n",
      "['gender']\n",
      "LIMIT\n",
      "\n",
      "SELECT gender,AVG(income) FROM pci_customers  WHERE state in ('Minnesota') GROUP BY gender ORDER BY gender\n",
      "1:  [('gender', 18, 24), ('state', 28, 37), ('income', 8, 14)]\n",
      "5\n",
      "SELECT\n",
      "['gender', 'AVG(income)']\n",
      "WHERE\n",
      "[\"state in ('Minnesota')\"]\n",
      "GROUP BY\n",
      "['gender']\n",
      "LIMIT\n",
      "\n",
      "SELECT gender,AVG(income) FROM pci_customers  WHERE state in ('Minnesota') GROUP BY gender ORDER BY gender\n",
      "1:  [('customer', 24, 29), ('gender', 24, 28), ('state', 33, 41), ('job', 0, 3)]\n",
      "3\n",
      "6\n",
      "SELECT\n",
      "['job', 'count(*)']\n",
      "WHERE\n",
      "[\"state in ('New York')\", \"gender in ('M')\"]\n",
      "GROUP BY\n",
      "['job']\n",
      "LIMIT\n",
      "\n",
      "SELECT job,count(*) FROM pci_customers  WHERE state in ('New York') AND gender in ('M') GROUP BY job ORDER BY job\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, jsonify, request, send_file\n",
    "from flask_sockets import Sockets\n",
    "from json import dumps\n",
    "import gevent\n",
    "import time\n",
    "import StringIO\n",
    "\n",
    "app = Flask(__name__)\n",
    "sockets = Sockets(app)\n",
    "\n",
    "@app.route('/voc')\n",
    "def voc():\n",
    "    try:\n",
    "        return render_template(\"voc.html\")\n",
    "    except Exception, e:\n",
    "        return str(e)\n",
    "\n",
    "@app.route('/720page/<name>')\n",
    "def foo_720page(name):\n",
    "    try:\n",
    "        return render_template(\"720page.html\", name=name)\n",
    "    except Exception, e:\n",
    "        return str(e)\n",
    "\n",
    "@app.route('/720view/<name>')\n",
    "def foo_720view(name):\n",
    "    try:\n",
    "        \"\"\"\n",
    "        customer = db.customers.find_one(\n",
    "            { 'name' :  name},\n",
    "            {'_id':  0,\n",
    "             'photo':1,\n",
    "             'name':1,\n",
    "             'phone':1,\n",
    "             'status':1}\n",
    "        )\n",
    "        \"\"\"\n",
    "        if name.lower()[:8]=='kathleen':\n",
    "            customer = {\n",
    "                'name': 'Kathleen Fanning',\n",
    "                'photo': '/static/images/photo_female.png',\n",
    "                'phone': '212-2222-245',\n",
    "                'status': 'Married'\n",
    "            }\n",
    "        else:\n",
    "            customer = {\n",
    "                'name': 'John Smith',\n",
    "                'photo': '/static/images/photo_male.png',\n",
    "                'phone': '212-2222-245',\n",
    "                'status': 'Married'\n",
    "            }\n",
    "        return render_template(\"720view.html\", customer=customer)\n",
    "    except Exception, e:\n",
    "        return str(e)\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "@sockets.route('/twitter_stream')\n",
    "def twitter_stream(ws):\n",
    "    j = 0\n",
    "    \n",
    "    conn = psycopg2.connect(database=\"twitter\", user=\"postgres\")\n",
    "    conn.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    curs = conn.cursor()\n",
    "    curs.execute(\"LISTEN new_tweet;\")\n",
    "    \n",
    "    while not ws.closed:\n",
    "        conn.poll()\n",
    "        t0 = time.time()\n",
    "        if conn.notifies:\n",
    "            notify = conn.notifies.pop(0)\n",
    "            \n",
    "            ws.send(\"{notification:\\'new tweet\\'}\")\n",
    "            j+=1\n",
    "        if time.time() - t0 > 3600:\n",
    "            print(\"1hr timeout\")\n",
    "            break\n",
    "        else:\n",
    "            gevent.sleep()\n",
    "    conn.close()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@app.route('/reply', methods=['POST'])\n",
    "def profile():\n",
    "    data = eval(request.form['py_data'])\n",
    "    status = request.form['status']\n",
    "    status_id = request.form['status_id']\n",
    "    \n",
    "    sentiment = data['sentiment']\n",
    "    user_name = data['user_name']\n",
    "    \n",
    "    tweet = twitter.statuses.update(status=status, in_reply_to_status_id=status_id)\n",
    "    \n",
    "    conn = psycopg2.connect(database=config[\"twitter_db\"][\"database\"], user=config[\"twitter_db\"][\"user\"])\n",
    "    conn.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    curs = conn.cursor()\n",
    "    \n",
    "    curs.execute(\"\"\"update customers\n",
    "                set got_reply=1\n",
    "                where user_screen_name=%s\"\"\",(tweet['in_reply_to_screen_name'],))\n",
    "    \n",
    "    curs.execute(\"\"\"insert into stream (id_str, text, created_at, in_reply_to_status_id,\n",
    "                in_reply_to_screen_name, user_screen_name, user_name, sentiment, is_agent_reply)\n",
    "                values (%s, %s, %s, %s, %s, %s, %s, %s, %s)\"\"\",\n",
    "                 (tweet['id_str'],\n",
    "                  tweet['text'],\n",
    "                  tweet['created_at'],\n",
    "                  tweet['in_reply_to_status_id'],\n",
    "                  tweet['in_reply_to_screen_name'],\n",
    "                  tweet['in_reply_to_screen_name'],\n",
    "                  user_name,\n",
    "                  sentiment,\n",
    "                  1,))\n",
    "    \n",
    "    conn.close()\n",
    "\n",
    "    return 'good'\n",
    "\n",
    "@app.route('/send_offer', methods=['POST'])\n",
    "def send_offer():\n",
    "    recipient_name = request.form['recipient-name']\n",
    "    message_text = request.form['message-text']\n",
    "    offer_image_id = request.form['offer-image-id']\n",
    "\n",
    "    gmail_user = config[\"gmail_user\"]\n",
    "    gmail_pass = config[\"gmail_pass\"]\n",
    "    gmail_recipient = config[\"gmail_recipient\"]\n",
    "    TO = gmail_recipient if type(gmail_recipient) is list else [gmail_recipient]\n",
    "\n",
    "    msg = MIMEMultipart('alternative')\n",
    "    msg['Subject'] = \"Special offer from CapBank\"\n",
    "    msg['From'] = \"VIP clients support team\"\n",
    "    msg['To'] = recipient_name\n",
    "    \n",
    "    fp = open(\"static/images/email/email_tmp\"+offer_image_id+\".png\", 'rb')\n",
    "    img_b64 = base64.b64encode(fp.read()).decode('ascii')\n",
    "    fp.close()\n",
    "\n",
    "    html = \"\"\"<html>\n",
    "      <head></head>\n",
    "      <body>\n",
    "        <img src=\"data:image/png;base64,{0}\" /><br />\n",
    "        <pre>{1}</pre>\n",
    "      </body>\n",
    "    </html>\"\"\".format(img_b64, message_text)\n",
    "    \n",
    "    # Record the MIME types of both parts - text/plain and text/html.\n",
    "    #part1 = MIMEText(text, 'plain')\n",
    "    part2 = MIMEText(html, 'html')    \n",
    "    \n",
    "    # Attach parts into message container.\n",
    "    # According to RFC 2046, the last part of a multipart message, in this case\n",
    "    # the HTML message, is best and preferred.\n",
    "    #msg.attach(part1)\n",
    "    msg.attach(part2)\n",
    "\n",
    "    try:\n",
    "        server = smtplib.SMTP(\"smtp.gmail.com\", 587)\n",
    "        server.ehlo()\n",
    "        server.starttls()\n",
    "        server.login(gmail_user, gmail_pass)\n",
    "        server.sendmail(gmail_user, gmail_recipient, msg.as_string())\n",
    "        server.close()\n",
    "        res = '<h4 class=\"bg-success\">E-mail sent successfully</h4>'\n",
    "    except:\n",
    "        res = '<h4 class=\"bg-danger\">E-mail sending failed</h4>'\n",
    "\n",
    "    return res\n",
    "\n",
    "@app.route('/delete_tweets', methods=['GET'])\n",
    "def delete_tweets():\n",
    "    try:\n",
    "        conn = psycopg2.connect(database=\"twitter\", user=\"postgres\")\n",
    "        conn.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "        curs = conn.cursor()\n",
    "\n",
    "        curs.execute(\"DELETE FROM stream WHERE user_screen_name = 'capgbanktest';\")\n",
    "        conn.close()\n",
    "        res = 'Deleted all tweets for `capgbanktest`'\n",
    "    except:\n",
    "        res = 'Failed to delete tweets'\n",
    "\n",
    "    return res\n",
    "\n",
    "@app.route('/data', methods=['GET'])\n",
    "def provide_data():\n",
    "    conn = psycopg2.connect(database=\"twitter\", user=\"postgres\")\n",
    "    conn.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    curs = conn.cursor()\n",
    "\n",
    "    curs.execute(\"\"\"select stream.user_screen_name, stream.user_name, stream.id_str,\n",
    "                stream.created_at, stream.sentiment, stream.categories, stream.text,\n",
    "                customers.klout_score, customers.segment, customers.got_reply, \n",
    "                customers.followers_count, stream.is_agent_reply\n",
    "                from stream\n",
    "                INNER JOIN customers\n",
    "                ON customers.user_screen_name=stream.user_screen_name\n",
    "                where stream.user_screen_name in \n",
    "                (\n",
    "                    select tmp.user_screen_name\n",
    "                    from (\n",
    "                        select user_screen_name as user_screen_name, max(id_str) as max_id_str\n",
    "                        from stream\n",
    "                        group by user_screen_name\n",
    "                    ) tmp\n",
    "                    left join (\n",
    "                        select user_screen_name, got_reply\n",
    "                        from customers\n",
    "                    ) tmp2\n",
    "                    on tmp.user_screen_name=tmp2.user_screen_name\n",
    "                    order by tmp2.got_reply asc, tmp.max_id_str desc limit 10\n",
    "                )\n",
    "                order by customers.got_reply desc, stream.id_str desc\n",
    "                ;\"\"\")\n",
    "    rec = curs.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    user_blocks = {v[0]:[] for v in rec}\n",
    "    for row in rec:\n",
    "        if len(user_blocks[row[0]]) < 10:\n",
    "            user_blocks[row[0]] += [{k:v for k,v in zip(field_names, row)}]\n",
    "            user_blocks[row[0]][-1]['id_str'] = str(user_blocks[row[0]][-1]['id_str'])\n",
    "            user_blocks[row[0]][-1]['segment'] = segment_dict[user_blocks[row[0]][-1]['segment_id']]\n",
    "    \n",
    "    user_blocks_v = user_blocks.values()\n",
    "    user_blocks_v_s = sorted(user_blocks_v, key=get_priority_key)\n",
    "    \n",
    "    return jsonify({'data':user_blocks_v_s})\n",
    "\n",
    "@app.route('/graph')\n",
    "def get_graph():\n",
    "    results = graph.cypher.execute(\n",
    "        \"match (p)-[r]->(p1) \"\n",
    "        \"where ((r.favorited>0 and r.retweeted>0) or (r.favorited>0 and r.replied>0) or (r.retweeted>0 and r.replied>0) \"\n",
    "        \"or (r.favorited>1) or (r.retweeted>1) or (r.replied>1)) and (not p=p1) \"\n",
    "        \"return p.screen_name, sum(r.favorited)+sum(r.retweeted)+sum(r.replied) as cardinality, p1.screen_name \"\n",
    "        \"limit 500;\")\n",
    "    nodes = []\n",
    "    rels = []\n",
    "\n",
    "    persons = {}\n",
    "    for person_b, cardinality, person_a in results:\n",
    "        if person_a in persons:\n",
    "            persons[person_a] += 1\n",
    "        else:\n",
    "            persons[person_a] = 1\n",
    "\n",
    "        if person_b not in persons:\n",
    "            persons[person_b] = 1\n",
    "\n",
    "    for i, v in persons.iteritems():\n",
    "        if i == u'gunjan_amit':\n",
    "            person = {\n",
    "                \"id\": persons.keys().index(i),\n",
    "                #\"caption\": i, \n",
    "                \"caption\": \"User\", \n",
    "                \"role\": \"center\"}\n",
    "        else:\n",
    "            person = {\n",
    "                \"id\": persons.keys().index(i),\n",
    "                \"caption\": i, \n",
    "                \"role\": \"customer\" if np.random.rand()>0.9 else \"user\",\n",
    "                }\n",
    "        nodes.append(person)\n",
    "\n",
    "    for person_b, cardinality, person_a in results:\n",
    "        person = {\"caption\": person_a, \"role\": \"customer\"}\n",
    "        source = persons.keys().index(person_a)\n",
    "        target = persons.keys().index(person_b)\n",
    "        rels.append({\"source\": source, \n",
    "            \"target\": target, \n",
    "            \"weight\": cardinality,\n",
    "            \"caption\": \"Value: {0}\".format(cardinality)\n",
    "            })\n",
    "\n",
    "    return jsonify({\"comment\": \"Tweeter users graph\", \"nodes\": nodes, \"edges\": rels})\n",
    "\n",
    "@app.route('/download/customers')\n",
    "def index():\n",
    "    strIO = StringIO.StringIO()\n",
    "    strIO.write('Customer Name, Status, Churn Rate\\n')\n",
    "#    for i in range(10):\n",
    "#        strIO.write(str(np.floor(10000*np.random.rand()))+',Credit Card\\n')\n",
    "    \n",
    "    cursor = db.customers.find().limit(103)\n",
    "    \n",
    "    for  c in cursor:\n",
    "        strIO.write(str(c['name'])+','+str(c['status'])+','+str(round(c['churn_rate']*100))+'%\\n')\n",
    "\n",
    "    strIO.seek(0)\n",
    "    return send_file(strIO,\n",
    "                     attachment_filename=\"Customers.csv\",\n",
    "                     as_attachment=True)\n",
    "\n",
    "@app.route('/map/get_customers/<state>')\n",
    "def map_get_customers(state):\n",
    "    try:\n",
    "        #cursor = db.customers.find({ 'state' : state })\n",
    "        cursor = db.customers.find(\n",
    "            { 'state' : state },\n",
    "            {'_id':  0,'customerId':1,'name':1,'churn_rate':1,'status':1}\n",
    "        )\n",
    "\n",
    "        status_weights = {'platinum':10,'gold':9,'silver':8,'bronze':7}\n",
    "\n",
    "        customers = []\n",
    "        for c in cursor:\n",
    "            c.update({'importance':status_weights[c['status'].lower()]*c['churn_rate']})\n",
    "            customers.append(c)\n",
    "\n",
    "        customers = sorted(customers, key=lambda x:-x['importance'])[:100]\n",
    "\n",
    "        customers = [[c['importance'],\n",
    "                      c['customerId'],\n",
    "                      c['name'],\n",
    "                      str(int(c['churn_rate']*100))+' %',\n",
    "                      c['status'],] \n",
    "                     for c in customers]\n",
    "        # Set selected user\n",
    "        customers[0][1] = 1\n",
    "        customers[0][2] = 'Kathleen Fanning'\n",
    "        customers[0][3] = '71 %'\n",
    "        return jsonify({'data':customers})\n",
    "    \n",
    "    except Exception, e:\n",
    "        return str(e)\n",
    "\n",
    "@app.route('/map/get_states_data')\n",
    "def map_states_data():\n",
    "    try:\n",
    "        with open('static/js/us-states.json') as f:\n",
    "            us_states_obj = json.load(f)\n",
    "\n",
    "        states_data = db.customers.aggregate([\n",
    "            {\"$group\": {\"_id\": \"$state\", \n",
    "                        'averageChurn': { '$avg': \"$churn_rate\" },\n",
    "                        \"count\": {\"$sum\": 1}}}])\n",
    "        states_data = {row['_id']:row for row in states_data}\n",
    "\n",
    "        states_data_objs = []\n",
    "\n",
    "        acc = 0\n",
    "        for i in range(len(us_states_obj['features'])):\n",
    "            state_name = us_states_obj['features'][i][u'properties']['name']\n",
    "            if state_name in states_data:\n",
    "                us_states_obj['features'][i]['properties'].update(states_data[state_name])\n",
    "                states_data_objs.append(us_states_obj['features'][i])\n",
    "\n",
    "        us_states_obj['features'] = states_data_objs\n",
    "\n",
    "        return jsonify(us_states_obj)\n",
    "    except Exception, e:\n",
    "        return str(e)\n",
    "\n",
    "@app.route('/map')\n",
    "def mappage():\n",
    "    try:\n",
    "        return render_template(\"map.html\")\n",
    "    except Exception, e:\n",
    "        return str(e)\n",
    "\n",
    "@app.route('/cluster')\n",
    "def clusterpage():\n",
    "    try:\n",
    "        return render_template(\"cluster.html\")\n",
    "    except Exception, e:\n",
    "        return str(e)\n",
    "\n",
    "@app.route('/nbo/<int:userid>')\n",
    "def nbopage(userid):\n",
    "    try:\n",
    "        cursor = db.customers.find({ 'customerId' : userid })\n",
    "        if cursor.count() < 1:\n",
    "            return render_template(\"nbo_no_such_user.html\")\n",
    "        mongo_record = cursor.next()\n",
    "    except Exception, e:\n",
    "        return str(e)\n",
    "\n",
    "    customer = {}\n",
    "    # General fields\n",
    "    data_list = ['name', 'status', 'state', 'maritalStatus', 'creditScoreFICO', 'email', \n",
    "                 'numberOfChildren', \"predictedLifeEvent\"]\n",
    "    for l in data_list:\n",
    "        customer[l] = mongo_record[l] if l in mongo_record else 'N/A' \n",
    "\n",
    "    # Fields with money\n",
    "    data_list = ['investableAssetEstimate', 'zillowHomeValueEstimation', 'homeEquityEstimate']\n",
    "    for l in data_list:\n",
    "        customer[l] = \"$ {0:,d}\".format(int(mongo_record[l])) if l in mongo_record else 'N/A'\n",
    "    \n",
    "    \n",
    "    # \"Profitability\" time series\n",
    "    timeseries = mongo_record['monthlyProfitabilities']\n",
    "\n",
    "    month_list = []\n",
    "    this_year_values = []\n",
    "    last_year_values = []\n",
    "\n",
    "    if len(timeseries) > 1:\n",
    "        timeseries = sorted(timeseries, key=lambda r: r['date'], reverse = True) # sort by year+month\n",
    "        timeseries = timeseries[:20] # keep no more than 20 last months\n",
    "\n",
    "        # make our data look like they are fresh\n",
    "        data_date = date(int(timeseries[0]['date'][:4]), int(timeseries[0]['date'][5:]), 1)\n",
    "        our_date = date.today()-relativedelta(months=1)\n",
    "\n",
    "        for i in range(0, 4):\n",
    "            month_list.append(our_date.strftime(\"%b\"))\n",
    "\n",
    "            look_for_date = \"{0}-{1:02d}\".format(data_date.year, data_date.month)\n",
    "            profitability = next( (r['profitability'] \n",
    "                                   for r in timeseries \n",
    "                                   if r['date']==look_for_date)\n",
    "                                 , None)\n",
    "            this_year_values.append(profitability)\n",
    "\n",
    "            look_for_date = \"{0}-{1:02d}\".format(data_date.year-1, data_date.month)\n",
    "            profitability = next( (r['profitability'] \n",
    "                                   for r in timeseries \n",
    "                                   if r['date']==look_for_date)\n",
    "                                 , None)\n",
    "            last_year_values.append(profitability)\n",
    "\n",
    "            our_date -= relativedelta(months=1)\n",
    "            data_date -= relativedelta(months=1)\n",
    "\n",
    "        month_list.reverse()\n",
    "        this_year_values.reverse()\n",
    "        last_year_values.reverse()\n",
    "    \n",
    "    customer['profitability_months'] = month_list\n",
    "    customer['profitability_this_year'] = this_year_values\n",
    "    customer['profitability_last_year'] = last_year_values\n",
    "\n",
    "    # \"Products\" time series\n",
    "    timeseries = mongo_record['products']\n",
    "    month_list = []\n",
    "    investment_values = []\n",
    "    savings_values = []\n",
    "    checking_values = []\n",
    "\n",
    "    if len(timeseries) > 1: \n",
    "        timeseries = sorted(timeseries, key=lambda r: r['yearAndMonth'], reverse = True)\n",
    "        timeseries = timeseries[:60] # keep no more than 60 last values (up to 20 months)\n",
    "\n",
    "        # make our data look like they are fresh\n",
    "        data_date = date(int(timeseries[0]['yearAndMonth'][:4]), # year\n",
    "                         int(timeseries[0]['yearAndMonth'][5:]), # month\n",
    "                         1)                                      # day\n",
    "        our_date = date.today()-relativedelta(months=1)\n",
    "\n",
    "        for i in range(0, 4):\n",
    "            month_list.append(our_date.strftime(\"%b\"))\n",
    "\n",
    "            look_for_date = \"{0}-{1:02d}\".format(data_date.year, data_date.month)\n",
    "            investment = next( (r['monthlyAverage'] \n",
    "                                for r in timeseries \n",
    "                                if r['yearAndMonth']==look_for_date and r['product']==\"Investment\")\n",
    "                              , None)\n",
    "            investment_values.append(investment)\n",
    "            savings = next( (r['monthlyAverage'] \n",
    "                                for r in timeseries \n",
    "                                if r['yearAndMonth']==look_for_date and r['product']==\"Savings\")\n",
    "                              , None)\n",
    "            savings_values.append(savings)\n",
    "            checking = next( (r['monthlyAverage'] \n",
    "                                for r in timeseries \n",
    "                                if r['yearAndMonth']==look_for_date and r['product']==\"Checking\")\n",
    "                              , None)\n",
    "            checking_values.append(checking)\n",
    "\n",
    "            our_date -= relativedelta(months=1)\n",
    "            data_date -= relativedelta(months=1)\n",
    "\n",
    "        month_list.reverse()\n",
    "        investment_values.reverse()\n",
    "        savings_values.reverse()\n",
    "        checking_values.reverse()\n",
    "\n",
    "    customer['products_months'] = month_list\n",
    "    customer['investment_values'] = investment_values\n",
    "    customer['savings_values'] = savings_values\n",
    "    customer['checking_values'] = checking_values\n",
    "\n",
    "    # \"Surveys\" time series\n",
    "    timeseries = mongo_record['surveys']\n",
    "    surveys_data = []\n",
    "    last4years = []\n",
    "    \n",
    "    if len(timeseries) > 0: \n",
    "        years_show = 4\n",
    "        timeseries = sorted(timeseries, key=lambda r: r['surveyDate'], reverse = True)\n",
    "        timeseries = timeseries[:years_show] # keep no more than 4 last values\n",
    "\n",
    "        # make our data look like they are for last 4 years\n",
    "        date_to = date.today()\n",
    "        for r in timeseries:\n",
    "            date_to = date_to-relativedelta(years=1)\n",
    "            surveys_data.append(r['surveyResult'])\n",
    "            last4years.append(date_to.year)\n",
    "        # fill empty values with None\n",
    "        for i in range(len(timeseries), years_show):\n",
    "            date_to = date_to-relativedelta(years=1)\n",
    "            surveys_data.append(None)\n",
    "            last4years.append(date_to.year)\n",
    "\n",
    "    surveys_data.reverse()\n",
    "    last4years.reverse()\n",
    "    customer['surveys_data'] = surveys_data\n",
    "    customer['last4years'] = last4years\n",
    "\n",
    "    nbo_offers = mongo_record['nextBestOffers']\n",
    "    if len(nbo_offers) > 0: \n",
    "        nbo_offers = sorted(nbo_offers, key=lambda r: r['nboProbability'], reverse = True)\n",
    "        i = 1\n",
    "        for r in nbo_offers:\n",
    "            r['nboProbability'] = \"{0:.1f}%\".format(r['nboProbability']*100.0)\n",
    "            r['index'] = i\n",
    "            i += 1\n",
    "    customer['nbo_offers'] = nbo_offers\n",
    "    \n",
    "#    customer['suboffers'] = suboffers\n",
    "\n",
    "    # List of last 4 months\n",
    "    customer['last4months'] = [(date.today()-relativedelta(months=a)).strftime('%b') for a in range(4,0,-1)]\n",
    "\n",
    "    try:\n",
    "        return render_template(\"nbo.html\", customer=customer)\n",
    "    except Exception, e:\n",
    "        return str(e)\n",
    "\n",
    "@app.route('/loopfeedback')\n",
    "def loopfeedbackpage():\n",
    "    try:\n",
    "        return render_template(\"loopfeedback.html\")\n",
    "    except Exception, e:\n",
    "        return str(e)\n",
    "\n",
    "@app.route('/loyalty')\n",
    "def loyaltypage():\n",
    "    try:\n",
    "        return render_template(\"loyalty.html\")\n",
    "    except Exception, e:\n",
    "        return str(e)\n",
    "\n",
    "@app.route('/wm', methods=['GET'])\n",
    "def wmpage():\n",
    "    try:\n",
    "        name = ''\n",
    "        status = 'ok'\n",
    "        if 'name' in request.args:\n",
    "            name = request.args['name']\n",
    "            if name.lower() == 'deborah winshel':\n",
    "                name = 'Deborah Winshel'\n",
    "            else:\n",
    "                name = str(name)\n",
    "                status = 'Not found'\n",
    "        else:\n",
    "            status = 'Search'\n",
    "        \n",
    "        return render_template(\"wm.html\", name=name, status=status)\n",
    "    except Exception, e:\n",
    "        return str(e)\n",
    "\n",
    "@app.route('/pci')\n",
    "def pcipage():\n",
    "    try:\n",
    "        return render_template(\"pci.html\")\n",
    "    except Exception, e:\n",
    "        return str(e)\n",
    "\n",
    "@app.route('/send_pci_query', methods=['POST'])\n",
    "def send_pci_query():\n",
    "    query_text = request.form['query']\n",
    "\n",
    "    def err_msg(text = 'Cannot understand you query, please try to paraphrase it'):\n",
    "        return jsonify({'error': 'yes', 'error_text': text,  'query': query_text})\n",
    "\n",
    "    def one_hot_dataframe(data, cols, replace=False):\n",
    "        vec = DictVectorizer()\n",
    "        mkdict = lambda row: dict((col, row[col]) for col in cols)\n",
    "        vecData = pandas.DataFrame(vec.fit_transform(data[cols].apply(mkdict, axis=1)).toarray())\n",
    "        vecData.columns = vec.get_feature_names()\n",
    "        vecData.index = data.index\n",
    "        if replace is True:\n",
    "            data = data.drop(cols, axis=1)\n",
    "            data = data.join(vecData)\n",
    "        return (data, vecData, vec)\n",
    "\n",
    "\n",
    "    query = parse_query.parse_it(query_text)\n",
    "\n",
    "    # check if it is predictive query\n",
    "    if query and 'parameters' in query and 'mode' in query['parameters'] and query['parameters']['mode'] == 'model':\n",
    "        #search for target variable\n",
    "        target = None\n",
    "        target_variables = ['debt_funds', 'credit_card']\n",
    "        new_filter = []\n",
    "        for sel in query['sql_filter']:\n",
    "            for var in target_variables:\n",
    "                if var in sel:\n",
    "                    target = var\n",
    "                    break \n",
    "            else: # do not keep target variable in filter list (for-else python structure)\n",
    "                new_filter.append(sel) \n",
    "\n",
    "        if target == None: \n",
    "            return err_msg('Cannot understand you query, please try to paraphrase it') # couldn't find target \n",
    "        \n",
    "        parameters = set([\"age\" , \"job\" , \"marital\" , \"education\" , \"debt_funds\" , \"credit_card\" , \n",
    "                          \"income\" , \"state\" , \"gender\"])\n",
    "        parameters = list(parameters - set([target]))\n",
    "        \n",
    "        sql_query = \"SELECT \" + target + \", \" + \", \".join(parameters) + \" FROM pci_customers\"\n",
    "        if new_filter: sql_query += \" WHERE \" + \" AND \".join(new_filter)\n",
    "\n",
    "        conn = psycopg2.connect(database=\"pci\", user=\"postgres\")\n",
    "\n",
    "        try:\n",
    "            full_df = pandas.read_sql(sql_query, conn)\n",
    "        except Exception, e:\n",
    "            return err_msg(str(e))\n",
    "\n",
    "        conn.close()\n",
    "        \n",
    "        y_name = full_df.keys()[0]\n",
    "        x = full_df.drop(y_name, axis=1)\n",
    "        y = full_df[y_name].copy()\n",
    "        \n",
    "        y.replace(to_replace=['no', 'yes'], value=[0, 1] , inplace = True)\n",
    "        x.replace(to_replace=['no', 'yes'], value=[0, 1] , inplace = True)\n",
    "        x.replace(to_replace=['F', 'M'], value=[0, 1] , inplace = True)\n",
    "        \n",
    "        x2, _, _ = one_hot_dataframe(x, ['state', 'marital', 'job', 'education'], replace=True)\n",
    "        \n",
    "        dtc = DecisionTreeClassifier(random_state=241, max_leaf_nodes=40, criterion='gini')\n",
    "        dtc.fit(x2, y)\n",
    "        feature_w = dict() # Feature weights\n",
    "        for i in range(len(x2.columns)):\n",
    "            if '=' in x2.columns[i]:\n",
    "                name = x2.columns[i].split('=')[0] # One-hot feature names are like 'job=student'\n",
    "            else:\n",
    "                name = x2.columns[i]\n",
    "            name = name.replace('_', ' ').capitalize()\n",
    "            if name in feature_w:\n",
    "                feature_w[name] += dtc.feature_importances_[i]\n",
    "            else:\n",
    "                feature_w[name] = dtc.feature_importances_[i]\n",
    "        \n",
    "        # Convert to descending list\n",
    "        #feature_w = sorted(feature_w.items(), key = lambda x: -x[1])\n",
    "        \n",
    "        # Convert to list (when unordered it looks better on spider-web type chart)\n",
    "        feature_w = feature_w.items()\n",
    "        \n",
    "        # fill with default data\n",
    "        charts = {'age': 0,\n",
    "                 'gender': 0,\n",
    "                 'state': 0,\n",
    "                 'credit_card': 0,\n",
    "                 'debt_funds': 0,\n",
    "                 'job': 0,\n",
    "                 'income': 0,\n",
    "                 'education': 0,\n",
    "                 'marital': 0}\n",
    "\n",
    "\n",
    "\n",
    "        # Predictors is list of tuples (<parameter>, <Parameter name>)\n",
    "        predictors = [('age', 'Age'), ('income', 'Income'), ('job', 'Job type'), ('education', 'Education level'),\n",
    "                     ('marital', 'Marital status'), ('gender', 'Gender')]\n",
    "        # Collect data\n",
    "        for predictor, pr_name in predictors:\n",
    "            if predictor == 'age':\n",
    "                series = full_df.groupby([ y_name, np.floor(full_df[predictor]/10)*10 ]).count()['age']\n",
    "            elif predictor == 'income':\n",
    "                series = full_df.groupby([ y_name, np.floor(full_df[predictor]/1000)*1000 ]).count()['age']\n",
    "            else:\n",
    "                series = full_df.groupby([y_name, predictor]).count()['age']\n",
    "            \n",
    "            res_series = []\n",
    "            for i in series.index.levels[0]:\n",
    "                series_data = []\n",
    "                for k in series.index.levels[1]:\n",
    "                    if (i, k) in series:\n",
    "                        # append result as percentage\n",
    "                        series_data.append( floor(1000.0*series[(i, k)]/x2.shape[0])/10 )\n",
    "                    else:\n",
    "                        series_data.append( None )\n",
    "                series_name = \"Positive\" if i == \"yes\" else \"Negative\"\n",
    "                visibility = True if i == \"yes\" else False\n",
    "                res_series.append({\"name\": series_name, \"data\": series_data, \"visible\": visibility})\n",
    "            res_series.reverse()\n",
    "\n",
    "\n",
    "            params = {'name': pr_name}\n",
    "            if predictor == 'gender':\n",
    "                params['categories'] = [w.replace('F', 'Female').replace('M', 'Male') for w in series.index.levels[1]]\n",
    "            else:\n",
    "                params['categories'] = list(series.index.levels[1])\n",
    "            params['series'] = res_series\n",
    "\n",
    "            #save predictor to charts dictionary\n",
    "            charts[predictor.replace('_', ' ').capitalize()] = params\n",
    "            \n",
    "        # Collect States data \n",
    "        series = full_df.groupby([y_name, 'state']).count()['age']\n",
    "        states = dict()\n",
    "        # We'll calculate max and min values for map coloring\n",
    "        max_val = 0\n",
    "        min_val = 100\n",
    "        for k in series.index.levels[1]:\n",
    "            if ('yes', k) in series: yes = series[('yes', k)]\n",
    "            else: yes = 0\n",
    "            if ('no', k) in series: no = series[('no', k)]\n",
    "            else: no = 0\n",
    "            if yes+no > 0:\n",
    "                val = floor(yes*100/(yes+no))\n",
    "                states[k] = {\"value\": val}\n",
    "                if val > max_val: max_val = val\n",
    "                if val < min_val: min_val = val\n",
    "            else: states[k] = {\"value\": None}        \n",
    "        params = {'name': 'State distribution'}\n",
    "        params['states'] = states\n",
    "        params['minValue'] = min_val\n",
    "        params['maxValue'] = max_val\n",
    "\n",
    "        #save predictor to charts dictionary\n",
    "        charts['State'] = params\n",
    "\n",
    "        \n",
    "        \n",
    "        # Extract target groups from prediction\n",
    "\n",
    "        # Parse tree and return list of nodes with positive answers (value[id][0][1]>value[id][0][0])\n",
    "        # Uses global object 'dtc' of type sklearn.tree.DecisionTreeClassifier\n",
    "        # Return: [[node_id, [path_to_node]]....]\n",
    "        def travel_tree(node_id, path):\n",
    "            res = []\n",
    "            res_l = []\n",
    "            res_r = []\n",
    "            new_path_l = path + [(node_id, True)]\n",
    "            new_path_r = path + [(node_id, False)]\n",
    "            if dtc.tree_.children_left[node_id] != -1:\n",
    "                res_l = travel_tree(dtc.tree_.children_left[node_id], new_path_l)\n",
    "            if dtc.tree_.children_left[node_id] != -1:\n",
    "                res_r = travel_tree(dtc.tree_.children_right[node_id], new_path_r)\n",
    "\n",
    "            if dtc.tree_.value[node_id][0][1] > dtc.tree_.value[node_id][0][0]: # if it's positive node\n",
    "                res = [[node_id, path]]\n",
    "\n",
    "            return res + res_l + res_r\n",
    "        # end def travel_tree(node_id, path):\n",
    "        \n",
    "        # Desribes path in set of statements\n",
    "        # Uses global object 'dtc' of type sklearn.tree.DecisionTreeClassifier\n",
    "        def describe_path(path):\n",
    "            features = dict()\n",
    "            for i, truth in path:\n",
    "                f_name = x2.columns[dtc.tree_.feature[i]]\n",
    "                if f_name in ['credit_card', 'debt_funds']: # if feature is binary\n",
    "                    value = 'Has not' if truth else 'Has' # In the tree truth corresponds to value <= 0,5\n",
    "                    features[f_name] = value\n",
    "                elif f_name == 'gender':\n",
    "                    value = 'Female' if truth else 'Male'\n",
    "                    features[f_name] = value\n",
    "                elif '=' in f_name: # if feature is category\n",
    "                    f_name, value = f_name.split('=')\n",
    "                    if truth: # we do NOT want such value\n",
    "                        if f_name in features:\n",
    "                            features[f_name]['not_in'].append(value)\n",
    "                        else:\n",
    "                            features[f_name] = {'in': None, 'not_in': [value]}\n",
    "                    else: #we DO want such value\n",
    "                        if f_name in features:\n",
    "                            features[f_name]['in'] = value\n",
    "                        else:\n",
    "                            features[f_name] = {'in': value, 'not_in': []}\n",
    "                else: # feature is numeric\n",
    "                    value = dtc.tree_.threshold[i]\n",
    "                    if truth: # it is UPPER limit\n",
    "                        if f_name in features:\n",
    "                            features[f_name]['upper'] = value\n",
    "                        else:\n",
    "                            features[f_name] = {'lower': None, 'upper': value}\n",
    "                    else: #it is LOWER limit\n",
    "                        if f_name in features:\n",
    "                            features[f_name]['lower'] = value\n",
    "                        else:\n",
    "                            features[f_name] = {'lower': value, 'upper': None}\n",
    "            return features\n",
    "        #end def describe_path(path):\n",
    "        \n",
    "        positives = travel_tree(0, [])\n",
    "        \n",
    "        # Sort positives by absolute value, descending\n",
    "        positives = sorted(positives, key=lambda x: -dtc.tree_.value[x[0]][0][1])\n",
    "        \n",
    "        # get some samples (from 10%+1 to 20%+5)\n",
    "        positives = positives[len(positives)/10+1:len(positives)/5+5]\n",
    "        \n",
    "        # sort buy purity, descending\n",
    "        positives = sorted(positives, \n",
    "                key=lambda x: -dtc.tree_.value[x[0]][0][1]/(dtc.tree_.value[x[0]][0][0]+dtc.tree_.value[x[0]][0][1]) )\n",
    "        # Take no more than first 4\n",
    "        positives = positives[:4]\n",
    "        \n",
    "        targets = []\n",
    "        for i in range(len(positives)):\n",
    "            conditions=describe_path(positives[i][1])\n",
    "            val = dtc.tree_.value[positives[i][0]][0] # will be touple\n",
    "            percents = floor(val[1]/(val[0]+val[1])*1000)/10\n",
    "            targets.append({'conditions': conditions, 'percents': percents})\n",
    "        \n",
    "        res = jsonify({ 'type': 'model', 'title': '', 'query': query_text, 'features': feature_w, \n",
    "                       'charts': charts, 'targets': targets })\n",
    "\n",
    "    else: # not a model query\n",
    "        if not query or (not query['sql_select']): \n",
    "            return err_msg()\n",
    "\n",
    "        sql_query = \"SELECT \" + \",\".join(query['sql_select']) + \" FROM pci_customers \"\n",
    "        if query['sql_filter']:\n",
    "            sql_query += \" WHERE \" + \" AND \".join(query['sql_filter'])\n",
    "        if query['sql_group_by']:\n",
    "            sql_query += \" GROUP BY \" + \", \".join(query['sql_group_by']) \n",
    "            sql_query += \" ORDER BY \" + \", \".join(query['sql_group_by'])\n",
    "        if query['sql_limit']:\n",
    "            sql_query += \" LIMIT \" + query['sql_limit']\n",
    "\n",
    "        chartTitle = \"Shown: '\" + query['target']\n",
    "        if query['group_by'] and query['group_by'] != query['target']:\n",
    "            chartTitle += \" by \" + query['group_by'] + \"'\"\n",
    "        if query['sql_filter']:\n",
    "            chartTitle += \" Filter: \" + \" AND \".join(query['sql_filter']) + \"'\"\n",
    "\n",
    "        if query['group_by'] == \"state\":\n",
    "            chartType = \"map\"\n",
    "        elif query['group_by'] == \"gender\":\n",
    "            chartType = \"pie\"\n",
    "            category_ind = query['sql_select'].index('gender')\n",
    "        elif query['group_by'] == \"job\":\n",
    "            chartType = \"pie\"\n",
    "            category_ind = query['sql_select'].index('job')\n",
    "        elif query['group_by'] == \"education\":\n",
    "            chartType = \"pie\"\n",
    "            category_ind = query['sql_select'].index('education')\n",
    "        elif query['group_by']:\n",
    "            chartType = \"linear\"\n",
    "        else:\n",
    "            chartType = \"table\"\n",
    "  \n",
    "        xAxis = []\n",
    "        yAxis = []\n",
    "        print sql_query # debug\n",
    "\n",
    "        conn = psycopg2.connect(database=\"pci\", user=\"postgres\")\n",
    "        conn.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "        curs = conn.cursor()\n",
    "\n",
    "        try:\n",
    "            curs.execute(sql_query)\n",
    "        except Exception, e:\n",
    "            return err_msg()\n",
    "\n",
    "        rec = curs.fetchall()\n",
    "        conn.close()\n",
    "\n",
    "        res = err_msg()\n",
    "\n",
    "        if chartType == 'pie':\n",
    "            value_ind = 1 if category_ind == 0 else 0\n",
    "            for row in rec:\n",
    "                yAxis.append(round(row[value_ind]))\n",
    "                xAxis.append(row[category_ind])\n",
    "            res = jsonify({'type': chartType, 'title': chartTitle, 'xAxis': xAxis, 'yAxis': yAxis, 'query': query_text})\n",
    "\n",
    "        if chartType == 'linear': \n",
    "            for row in rec:\n",
    "                yAxis.append(round(row[0]))\n",
    "                xAxis.append(round(row[1]))\n",
    "            res = jsonify({'type': chartType, 'title': chartTitle, 'xAxis': xAxis, 'yAxis': yAxis,\n",
    "                          'query': query_text, 'xTitle': query['group_by'], 'yTitle': query['target'] })\n",
    "\n",
    "        if chartType == 'map':\n",
    "            states = dict()\n",
    "\n",
    "            # one of SELECT parameters will be state and other - values\n",
    "            state_ind = 0 if query['sql_select'][0] == 'state' else 1\n",
    "            count_ind = 1 if state_ind == 0 else 0\n",
    "\n",
    "            if len(rec)>0: max_val = rec[0][count_ind] # We'll calculate max and min values for map coloring\n",
    "            else: max_val = 0\n",
    "            min_val = max_val\n",
    "            for row in rec:\n",
    "                states[row[state_ind]] = {\"value\": round(row[count_ind])}\n",
    "                if round(row[count_ind]) > max_val: max_val = round(row[count_ind])\n",
    "                if round(row[count_ind]) < min_val: min_val = round(row[count_ind])\n",
    "            res = jsonify({'type': chartType, 'title': chartTitle, \n",
    "                           'xAxis': [], 'yAxis': [], \n",
    "                           'states': states, 'query': query_text,\n",
    "                           \"maxValue\": ceil(max_val), \"minValue\": floor(min_val)})\n",
    "\n",
    "    return res;\n",
    "\n",
    "@app.route('/test_speech')\n",
    "def test_speechpage():\n",
    "    try:\n",
    "        return render_template(\"test_speech.html\")\n",
    "    except Exception, e:\n",
    "        return str(e)\n",
    "\n",
    "@app.route('/')\n",
    "def welcomepage():\n",
    "    try:\n",
    "        return render_template(\"welcome.html\")\n",
    "    except Exception, e:\n",
    "        return str(e)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from gevent.pool import Pool\n",
    "    from gevent import pywsgi\n",
    "    from geventwebsocket.handler import WebSocketHandler\n",
    "    server = pywsgi.WSGIServer(('', 8091), app, handler_class=WebSocketHandler, spawn=Pool())\n",
    "    server.serve_forever()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
